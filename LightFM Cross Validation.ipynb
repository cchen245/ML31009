{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cchen245/anaconda3/lib/python3.7/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "#pip install LightFM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from lightfm.evaluation import auc_score\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Read all datasets\n",
    "# =============================================================================\n",
    "\n",
    "df_answer_scores = pd.read_csv('answer_scores.csv')\n",
    "df_answers = pd.read_csv('answers.csv',parse_dates=['answers_date_added'])\n",
    "df_comments = pd.read_csv('comments.csv')\n",
    "df_emails = pd.read_csv('emails.csv')\n",
    "df_group_memberships = pd.read_csv('group_memberships.csv')\n",
    "df_groups = pd.read_csv('groups.csv')\n",
    "df_matches = pd.read_csv('matches.csv')\n",
    "df_professionals = pd.read_csv('professionals.csv',parse_dates=['professionals_date_joined'])\n",
    "df_question_scores = pd.read_csv('question_scores.csv')\n",
    "df_questions = pd.read_csv('questions.csv',parse_dates=['questions_date_added'])\n",
    "df_school_memberships = pd.read_csv('school_memberships.csv')\n",
    "df_students = pd.read_csv('students.csv',parse_dates=['students_date_joined'])\n",
    "df_tag_questions = pd.read_csv('tag_questions.csv')\n",
    "df_tag_users = pd.read_csv('tag_users.csv')\n",
    "df_tags = pd.read_csv('tags.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Defining Necessary Functions\n",
    "# =============================================================================\n",
    "\n",
    "def generate_int_id(dataframe, id_col_name):\n",
    "    \"\"\"\n",
    "    Generate unique integer id for users, questions and answers\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        Pandas Dataframe for Users or Q&A. \n",
    "    id_col_name : String \n",
    "        New integer id's column name.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Dataframe\n",
    "        Updated dataframe containing new id column \n",
    "    \"\"\"\n",
    "    new_dataframe=dataframe.assign(\n",
    "        int_id_col_name=np.arange(len(dataframe))\n",
    "        ).reset_index(drop=True)\n",
    "    return new_dataframe.rename(columns={'int_id_col_name': id_col_name})\n",
    "\n",
    "#create features \n",
    "def create_features(dataframe, features_name, id_col_name):\n",
    "    \"\"\"\n",
    "    Generate features that will be ready for feeding into lightfm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        Pandas Dataframe which contains features\n",
    "    features_name : List\n",
    "        List of feature columns name avaiable in dataframe\n",
    "    id_col_name: String\n",
    "        Column name which contains id of the question or\n",
    "        answer that the features will map to.\n",
    "        There are two possible values for this variable.\n",
    "        1. questions_id_num\n",
    "        2. professionals_id_num\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas Series\n",
    "        A pandas series containing process features\n",
    "        that are ready for feed into lightfm.\n",
    "        The format of each value\n",
    "        will be (user_id, ['feature_1', 'feature_2', 'feature_3'])\n",
    "        Ex. -> (1, ['military', 'army', '5'])\n",
    "    \"\"\"\n",
    "\n",
    "    features = dataframe[features_name].apply(\n",
    "        lambda x: ','.join(x.map(str)), axis=1)\n",
    "    features = features.str.split(',')\n",
    "    features = list(zip(dataframe[id_col_name], features))\n",
    "    return features\n",
    "\n",
    "#Generate feature listing\n",
    "def generate_feature_list(dataframe, features_name):\n",
    "    \"\"\"\n",
    "    Generate features list for mapping \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        Pandas Dataframe for Users or Q&A. \n",
    "    features_name : List\n",
    "        List of feature columns name avaiable in dataframe. \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List of all features for mapping \n",
    "    \"\"\"\n",
    "    features = dataframe[features_name].apply(\n",
    "        lambda x: ','.join(x.map(str)), axis=1)\n",
    "    features = features.str.split(',')\n",
    "    features = features.apply(pd.Series).stack().reset_index(drop=True)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Calculate AUC score\n",
    "def calculate_auc_score(lightfm_model, interactions_matrix, \n",
    "                        question_features, professional_features): \n",
    "    \"\"\"\n",
    "    Measure the ROC AUC metric for a model. \n",
    "    A perfect score is 1.0.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lightfm_model: LightFM model \n",
    "        A fitted lightfm model \n",
    "    interactions_matrix : \n",
    "        A lightfm interactions matrix \n",
    "    question_features, professional_features: \n",
    "        Lightfm features \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    String containing AUC score \n",
    "    \"\"\"\n",
    "    score = auc_score( \n",
    "        lightfm_model, interactions_matrix, \n",
    "        item_features=question_features, \n",
    "        user_features=professional_features, \n",
    "        num_threads=4).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Data Preprocessing and Feature Selection\n",
    "# =============================================================================\n",
    "\n",
    "# Generate numeric identifier\n",
    "df_professionals = generate_int_id(df_professionals, 'professionals_id_num')\n",
    "df_students = generate_int_id(df_students, 'students_id_num')\n",
    "df_questions = generate_int_id(df_questions, 'questions_id_num')\n",
    "df_answers = generate_int_id(df_answers, 'answers_id_num')\n",
    "\n",
    "# Merging Datasets\n",
    "# Tags: dropna from tags \n",
    "df_tags = df_tags.dropna()\n",
    "df_tags['tags_tag_name'] = df_tags['tags_tag_name'].str.replace('#', '')\n",
    "\n",
    "\n",
    "# Merge tag_questions with tags name\n",
    "# then group all tags for each question into single rows\n",
    "df_tags_question = df_tag_questions.merge(\n",
    "    df_tags, how='inner',\n",
    "    left_on='tag_questions_tag_id', right_on='tags_tag_id')\n",
    "df_tags_question = df_tags_question.groupby(\n",
    "    ['tag_questions_question_id'])['tags_tag_name'].apply(\n",
    "        ','.join).reset_index()\n",
    "df_tags_question = df_tags_question.rename(columns={'tags_tag_name': 'questions_tag_name'})\n",
    "\n",
    "# Merge tag_users with tags name \n",
    "# then group all tags for each user into single rows \n",
    "# after that rename the tag column name \n",
    "df_tags_pro = df_tag_users.merge(\n",
    "    df_tags, how='inner',\n",
    "    left_on='tag_users_tag_id', right_on='tags_tag_id')\n",
    "df_tags_pro = df_tags_pro.groupby(\n",
    "    ['tag_users_user_id'])['tags_tag_name'].apply(\n",
    "        ','.join).reset_index()\n",
    "df_tags_pro = df_tags_pro.rename(columns={'tags_tag_name': 'professionals_tag_name'})\n",
    "\n",
    "# Merge professionals and questions tags with main merge_dataset \n",
    "df_questions = df_questions.merge(\n",
    "    df_tags_question, how='left',\n",
    "    left_on='questions_id', right_on='tag_questions_question_id')\n",
    "df_professionals = df_professionals.merge(\n",
    "    df_tags_pro, how='left',\n",
    "    left_on='professionals_id', right_on='tag_users_user_id')\n",
    "\n",
    "# Merge questions with scores \n",
    "df_questions = df_questions.merge(\n",
    "    df_question_scores, how='left',\n",
    "    left_on='questions_id', right_on='id')\n",
    "# Merge questions with students \n",
    "df_questions = df_questions.merge(\n",
    "    df_students, how='left',\n",
    "    left_on='questions_author_id', right_on='students_id')\n",
    "\n",
    "# Merge answers with questions \n",
    "# then merge professionals and questions score with that \n",
    "df_merge = df_answers.merge(\n",
    "    df_questions, how='inner',\n",
    "    left_on='answers_question_id', right_on='questions_id')\n",
    "df_merge = df_merge.merge(\n",
    "    df_professionals, how='inner',\n",
    "    left_on='answers_author_id', right_on='professionals_id')\n",
    "df_merge = df_merge.merge(\n",
    "    df_question_scores, how='inner',\n",
    "    left_on='questions_id', right_on='id')\n",
    "\n",
    "# Save merged dataset for future use\n",
    "df_merge.to_csv('careervillage_merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of answer per question : 58\n",
      "Maximum number of tags per professional : 82.0\n",
      "Maximum number of tags per question : 54.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate some features\n",
    "# =============================================================================\n",
    "# Generate some features for calculates weights\n",
    "# that will use with interaction matrix \n",
    "# =============================================================================\n",
    "\n",
    "df_merge['num_of_ans_by_professional'] = df_merge.groupby(['answers_author_id'])['questions_id'].transform('count')\n",
    "df_merge['num_ans_per_ques'] = df_merge.groupby(['questions_id'])['answers_id'].transform('count')\n",
    "df_merge['num_tags_professional'] = df_merge['professionals_tag_name'].str.split(\",\").str.len()\n",
    "df_merge['num_tags_question'] = df_merge['questions_tag_name'].str.split(\",\").str.len()\n",
    "\n",
    "print(\"Maximum number of answer per question : \" + str(df_merge['num_ans_per_ques'].max()))\n",
    "print(\"Maximum number of tags per professional : \" + str(df_merge['num_tags_professional'].max()))\n",
    "print(\"Maximum number of tags per question : \" + str(df_merge['num_tags_question'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge answered questions tags with professional tags\n",
    "########################\n",
    "# Merge professionals previous answered \n",
    "# questions tags into professionals tags \n",
    "########################\n",
    "\n",
    "# select professionals answered questions tags \n",
    "# and stored as a dataframe\n",
    "professionals_prev_ans_tags = df_merge[['professionals_id', 'questions_tag_name']]\n",
    "# drop null values from that \n",
    "professionals_prev_ans_tags = professionals_prev_ans_tags.dropna()\n",
    "# because professsionals answers multiple questions, \n",
    "# we group all of tags of each user into single row \n",
    "professionals_prev_ans_tags = professionals_prev_ans_tags.groupby(\n",
    "    ['professionals_id'])['questions_tag_name'].apply(\n",
    "        ','.join).reset_index()\n",
    "\n",
    "# drop duplicates tags from each professionals rows\n",
    "professionals_prev_ans_tags['questions_tag_name'] = (\n",
    "    professionals_prev_ans_tags['questions_tag_name'].str.split(',').apply(set).str.join(','))\n",
    "\n",
    "# finally merge the dataframe with professionals dataframe \n",
    "df_professionals = df_professionals.merge(professionals_prev_ans_tags, how='left', on='professionals_id')\n",
    "\n",
    "# join professionals tags and their answered tags \n",
    "# we replace nan values with \"\"\n",
    "df_professionals['professional_all_tags'] = (\n",
    "    df_professionals[['professionals_tag_name', 'questions_tag_name']].apply(\n",
    "        lambda x: ','.join(x.dropna()),\n",
    "        axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Null and Duplicate Values\n",
    "# handling null values \n",
    "df_questions['score'] = df_questions['score'].fillna(0)\n",
    "df_questions['score'] = df_questions['score'].astype(int)\n",
    "df_questions['questions_tag_name'] = df_questions['questions_tag_name'].fillna('No Tag')\n",
    "# remove duplicates tags from each questions \n",
    "df_questions['questions_tag_name'] = df_questions['questions_tag_name'].str.split(',').apply(set).str.join(',')\n",
    "\n",
    "# fill nan with 'No Tag' if any \n",
    "df_professionals['professional_all_tags'] = df_professionals['professional_all_tags'].fillna('No Tag')\n",
    "# replace \"\" with \"No Tag\", because previously we replace nan with \"\"\n",
    "df_professionals['professional_all_tags'] = df_professionals['professional_all_tags'].replace('', 'No Tag')\n",
    "df_professionals['professionals_location'] = df_professionals['professionals_location'].fillna('No Location')\n",
    "df_professionals['professionals_industry'] = df_professionals['professionals_industry'].fillna('No Industry')\n",
    "\n",
    "# remove duplicates tags from each professionals \n",
    "df_professionals['professional_all_tags'] = df_professionals['professional_all_tags'].str.split(',').apply(set).str.join(',')\n",
    "\n",
    "# remove some null values from df_merge\n",
    "df_merge['num_ans_per_ques']  = df_merge['num_ans_per_ques'].fillna(0)\n",
    "df_merge['num_tags_professional'] = df_merge['num_tags_professional'].fillna(0)\n",
    "df_merge['num_tags_question'] = df_merge['num_tags_question'].fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Building LightFM Model\n",
    "# =============================================================================\n",
    "\n",
    "# Creating features list for Dataset class\n",
    "# generating features list for mapping \n",
    "question_feature_list = generate_feature_list(\n",
    "    df_questions,\n",
    "    ['questions_tag_name'])\n",
    "\n",
    "professional_feature_list = generate_feature_list(\n",
    "    df_professionals,\n",
    "    ['professional_all_tags'])\n",
    "\n",
    "# calculate our weight value \n",
    "df_merge['total_weights'] = 1 / (\n",
    "    df_merge['num_ans_per_ques'])\n",
    "\n",
    "# creating features for feeding into lightfm \n",
    "df_questions['question_features'] = create_features(\n",
    "    df_questions, ['questions_tag_name'], \n",
    "    'questions_id_num')\n",
    "\n",
    "df_professionals['professional_features'] = create_features(\n",
    "    df_professionals,\n",
    "    ['professional_all_tags'],\n",
    "    'professionals_id_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<23931x31023 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 101127 stored elements in Compressed Sparse Row format>\n",
      "(23931, 31023)\n",
      "<28152x41033 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 256988 stored elements in Compressed Sparse Row format>\n",
      "(28152, 41033)\n",
      "(1, 31023)\n",
      "[array([0, 0, 0], dtype=int32), array([    3, 23938, 23939], dtype=int32)]\n",
      "(1, 41033)\n",
      "The dataset has 28152 users and 23931 items, with 10020 interactions in the test and 40078 interactions in the training set.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LightFM Dataset\n",
    "########################\n",
    "# Dataset building for lightfm\n",
    "########################\n",
    "\n",
    "# define our dataset variable\n",
    "# then we feed unique professionals and questions ids\n",
    "# and item and professional feature list\n",
    "# this will create lightfm internel mapping\n",
    "dataset = Dataset()\n",
    "dataset.fit(\n",
    "    set(df_professionals['professionals_id_num']), \n",
    "    set(df_questions['questions_id_num']),\n",
    "    item_features=question_feature_list, \n",
    "    user_features=professional_feature_list)\n",
    "\n",
    "# now we are building interactions matrix between professionals and quesitons\n",
    "# we are passing professional and questions id as a tuple\n",
    "# e.g -> pd.Series((pro_id, question_id), (pro_id, questin_id))\n",
    "# then we use lightfm build in method for building interactions matrix\n",
    "df_merge['author_question_id_tuple'] = list(zip(\n",
    "    df_merge.professionals_id_num, df_merge.questions_id_num, df_merge.total_weights))\n",
    "\n",
    "interactions, weights = dataset.build_interactions(\n",
    "    df_merge['author_question_id_tuple'])\n",
    "\n",
    "# now we are building our questions and professionals features\n",
    "# in a way that lightfm understand.\n",
    "# we are using lightfm build in method for building\n",
    "# questions and professionals features \n",
    "questions_features = dataset.build_item_features(\n",
    "    df_questions['question_features'])\n",
    "\n",
    "professional_features = dataset.build_user_features(\n",
    "    df_professionals['professional_features'])\n",
    "\n",
    "print(repr(questions_features))\n",
    "print(questions_features.shape)\n",
    "\n",
    "print(repr(professional_features))\n",
    "print(professional_features.shape)\n",
    "\n",
    "# check features to see if weights make sense\n",
    "idx = 3\n",
    "tt = list(questions_features[idx].nonzero())\n",
    "print(questions_features[idx].shape)\n",
    "print(tt)\n",
    "\n",
    "uu = list(professional_features[idx].nonzero())\n",
    "print(professional_features[idx].shape)\n",
    "uu\n",
    "\n",
    "# Train-test split\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "seed = 7\n",
    "train,test=random_train_test_split(interactions,test_percentage=0.2,random_state=np.random.RandomState(seed))\n",
    "train_weight,test_weight=random_train_test_split(weights,test_percentage=0.2,random_state=np.random.RandomState(seed))\n",
    "\n",
    "print('The dataset has %s users and %s items, '\n",
    "      'with %s interactions in the test and %s interactions in the training set.'\n",
    "      % (train.shape[0], train.shape[1], test.getnnz(), train.getnnz()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7fa53446ebe0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################\n",
    "# Model building part\n",
    "################################\n",
    "\n",
    "# define lightfm model by specifying hyper-parameters\n",
    "# then fit the model with ineteractions matrix, item and user features \n",
    "\n",
    "# Pure Collaborative Filtering model\n",
    "NUM_THREADS = 4\n",
    "k = 5\n",
    "model_cf = LightFM(loss='logistic',\n",
    "                random_state=seed)\n",
    "\n",
    "model_cf.fit(train,epochs=5,num_threads=NUM_THREADS)\n",
    "\n",
    "# Hybrid Model\n",
    "NUM_THREADS = 4\n",
    "k = 5\n",
    "model_hybrid = LightFM(loss='warp',\n",
    "                       no_components=150,\n",
    "                       learning_rate=0.05,\n",
    "                       random_state=seed)\n",
    "\n",
    "# time it.\n",
    "model_hybrid.fit(train,\n",
    "                 item_features=questions_features,\n",
    "                 user_features=professional_features, \n",
    "                 sample_weight=train_weight,\n",
    "                 epochs=5, num_threads=4, verbose=True)\n",
    "\n",
    "model = LightFM(\n",
    "    no_components=150,\n",
    "    learning_rate=0.05,\n",
    "    loss='warp',\n",
    "    random_state=7)\n",
    "\n",
    "model.fit(\n",
    "    interactions,\n",
    "    item_features=questions_features,\n",
    "    user_features=professional_features, sample_weight=weights,\n",
    "    epochs=5, num_threads=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collaborative filtering train AUC: 0.8033621\n",
      "Collaborative filtering test AUC: 0.56643796\n",
      "Train precision: 0.0032\n",
      "Test precision: 0.0020\n",
      "Hybrid filtering train AUC: 0.8995613\n",
      "Hybrid filtering test AUC: 0.8476222\n",
      "Train precision: 0.0046\n",
      "Test precision: 0.0018\n",
      "Hybrid filtering train AUC: 0.9101777\n",
      "Train precision: 0.0056\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# Evaluating the Performance of the Model\n",
    "# =============================================================================\n",
    "\n",
    "# Pure Collaborative Filtering model\n",
    "train_auc = auc_score(model_cf, train, num_threads=NUM_THREADS).mean()\n",
    "print('Collaborative filtering train AUC: %s' % train_auc)\n",
    "# 0.8033621\n",
    "test_auc = auc_score(model_cf, test, num_threads=NUM_THREADS).mean()\n",
    "print('Collaborative filtering test AUC: %s' % test_auc)\n",
    "# 0.56643796\n",
    "\n",
    "from lightfm.evaluation import precision_at_k \n",
    "\n",
    "print(\"Train precision: %.4f\" % precision_at_k(model_cf, train, \n",
    "                                               k=k,num_threads=NUM_THREADS).mean())\n",
    "# 0.0032\n",
    "print(\"Test precision: %.4f\" % precision_at_k(model_cf, test,\n",
    "                                              # train_interactions=train, \n",
    "                                              k=k,num_threads=NUM_THREADS).mean())\n",
    "# 0.0020\n",
    "\n",
    "# Hybrid Model\n",
    "train_auc = auc_score(model_hybrid, train, \n",
    "                      user_features=professional_features, \n",
    "                      item_features=questions_features,\n",
    "                      num_threads=4).mean()\n",
    "print('Hybrid filtering train AUC: %s' % train_auc)\n",
    "# 0.8999492\n",
    "\n",
    "test_auc = auc_score(model_hybrid, test,\n",
    "                     user_features=professional_features, \n",
    "                     item_features=questions_features,\n",
    "                     num_threads=4).mean()\n",
    "print('Hybrid filtering test AUC: %s' % test_auc)\n",
    "# 0.8474504\n",
    "\n",
    "print(\"Train precision: %.4f\" % precision_at_k(model_hybrid, train, k=k, \n",
    "                                               user_features=professional_features, \n",
    "                                               item_features=questions_features,\n",
    "                                               num_threads=NUM_THREADS).mean())\n",
    "# 0.0051\n",
    "\n",
    "print(\"Test precision: %.4f\" % precision_at_k(model_hybrid, test,\n",
    "                                              user_features=professional_features, \n",
    "                                              item_features=questions_features,\n",
    "                                              # train_interactions=train, \n",
    "                                              k=k,num_threads=NUM_THREADS).mean())\n",
    "# 0.0016\n",
    "\n",
    "# AUC score higher for the Hybrid model, so use that for recommendations\n",
    "\n",
    "# All data used in Hybrid model\n",
    "train_auc = auc_score(model, train, \n",
    "                      user_features=professional_features, \n",
    "                      item_features=questions_features,\n",
    "                      num_threads=4).mean()\n",
    "print('Hybrid filtering train AUC: %s' % train_auc)\n",
    "# 0.91189903\n",
    "\n",
    "print(\"Train precision: %.4f\" % precision_at_k(model, train, k=k, \n",
    "                                               user_features=professional_features, \n",
    "                                               item_features=questions_features,\n",
    "                                               num_threads=NUM_THREADS).mean())\n",
    "# 0.0054\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional Id (3): Previous Answered Questions\n",
      "                                         questions_title  \\\n",
      "11339  What are the different jobs a person can do in...   \n",
      "14818  What does a typical work day for a forensic sc...   \n",
      "19077  Is most of your day spent working when being a...   \n",
      "\n",
      "                                     question_features  \n",
      "11339  (11339, [justice, science, criminal, forensic])  \n",
      "14818                                (14818, [No Tag])  \n",
      "19077                             (19077, [detective])      professionals_id_num professionals_tag_name\n",
      "3                     3                    NaN\n",
      "Professional Id (3): Recommended Questions: \n",
      "                                         questions_title  \\\n",
      "7918      what course should I opt to be a psychiatrist?   \n",
      "14774  What other career fields are open to someone w...   \n",
      "18568         What are the most prestigious law schools?   \n",
      "20640  What are the average amount of hours that a ha...   \n",
      "16081  i want to become a web developer?which subject...   \n",
      "23504                                   became a teacher   \n",
      "13906  Which course is valuable at present.?Please gu...   \n",
      "23677   How has studying anthropology changed your life?   \n",
      "\n",
      "                      question_features  \n",
      "7918             (7918, [psychiatrist])  \n",
      "14774  (14774, [international-affairs])  \n",
      "18568               (18568, [attorney])  \n",
      "20640           (20640, [hairdressers])  \n",
      "16081           (16081, [professional])  \n",
      "23504       (23504, [teacher-training])  \n",
      "13906                 (13906, [No Tag])  \n",
      "23677           (23677, [anthropology])  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cchen245/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Making Recommendations\n",
    "# =============================================================================\n",
    "\n",
    "from IPython.display import display_html\n",
    "\n",
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)\n",
    "    \n",
    "def recommend_questions1(professional_ids):\n",
    "     \n",
    "    for professional in professional_ids:\n",
    "        # print their previous answered question title\n",
    "        previous_q_id_num = df_merge.loc[df_merge['professionals_id_num'] == professional][:3]['questions_id_num']\n",
    "        df_previous_questions = df_questions.loc[df_questions['questions_id_num'].isin(previous_q_id_num)]\n",
    "        print('Professional Id (' + str(professional) + \"): Previous Answered Questions\")\n",
    "        print(\n",
    "            df_previous_questions[['questions_title', 'question_features']],\n",
    "            df_professionals.loc[df_professionals.professionals_id_num == professional][['professionals_id_num','professionals_tag_name']]\n",
    "            )\n",
    "        \n",
    "        # predict\n",
    "        discard_qu_id = df_previous_questions['questions_id_num'].values.tolist()\n",
    "        df_use_for_prediction = df_questions.loc[~df_questions['questions_id_num'].isin(discard_qu_id)]\n",
    "        questions_id_for_predict = df_use_for_prediction['questions_id_num'].values.tolist()\n",
    "        \n",
    "        scores = model.predict(\n",
    "            professional,\n",
    "            questions_id_for_predict)\n",
    "        \n",
    "        df_use_for_prediction['scores'] = scores\n",
    "        df_use_for_prediction = df_use_for_prediction.sort_values(by='scores', ascending=False)[:8]\n",
    "        print('Professional Id (' + str(professional) + \"): Recommended Questions: \")\n",
    "        print(df_use_for_prediction[['questions_title', 'question_features']])\n",
    "        \n",
    "recommend_questions1([3])        \n",
    "\n",
    "# =============================================================================\n",
    "# Additons\n",
    "# =============================================================================\n",
    "\n",
    "# https://sites.northwestern.edu/msia/2019/04/24/personalized-restaurant-recommender-system-using-hybrid-approach/\n",
    "# https://github.com/Ivanclj/Yelp-Recommender/blob/master/Restaurant%20Recommender.ipynb\n",
    "\n",
    "# from lightfm.cross_validation import random_train_test_split\n",
    "# train,test=random_train_test_split(interactions,test_percentage=0.2,random_state=np.random.RandomState(seed))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
